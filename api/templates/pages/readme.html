<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>DIE - Read me</title>
       <link rel="apple-touch-icon" sizes="57x57" href="{{ url_for('static', filename='images/fav/apple-icon-57x57.png') }}">
    <link rel="apple-touch-icon" sizes="60x60" href="{{ url_for('static', filename='images/fav/apple-icon-60x60.png') }}">
    <link rel="apple-touch-icon" sizes="72x72" href="{{ url_for('static', filename='images/fav/apple-icon-72x72.png') }}">
    <link rel="apple-touch-icon" sizes="76x76" href="{{ url_for('static', filename='images/fav/apple-icon-76x76.png') }}">
    <link rel="apple-touch-icon" sizes="114x114" href="{{ url_for('static', filename='images/fav/apple-icon-114x114.png') }}">
    <link rel="apple-touch-icon" sizes="120x120" href="{{ url_for('static', filename='images/fav/apple-icon-120x120.png') }}">
    <link rel="apple-touch-icon" sizes="144x144" href="{{ url_for('static', filename='images/fav/apple-icon-144x144.png') }}">
    <link rel="apple-touch-icon" sizes="152x152" href="{{ url_for('static', filename='images/fav/apple-icon-152x152.png') }}">
    <link rel="apple-touch-icon" sizes="180x180" href="{{ url_for('static', filename='images/fav/apple-icon-180x180.png') }}">
    <link rel="icon" type="image/png" sizes="192x192"  href="{{ url_for('static', filename='images/fav/android-icon-192x192.png') }}">
    <link rel="icon" type="image/png" sizes="32x32" href="{{ url_for('static', filename='images/fav/favicon-32x32.png') }}">
    <link rel="icon" type="image/png" sizes="96x96" href="{{ url_for('static', filename='images/fav/favicon-96x96.png') }}">
    <link rel="icon" type="image/png" sizes="16x16" href="{{ url_for('static', filename='images/fav/favicon-16x16.png') }}">
    <link rel="manifest" href="{{ url_for('static', filename='images/fav/manifest.json') }}">
    <meta name="msapplication-TileColor" content="#ffffff">
    <meta name="msapplication-TileImage" content="{{ url_for('static', filename='images/fav/ms-icon-144x144.png') }}">
    <meta name="theme-color" content="#ffffff">

    <link rel='stylesheet prefetch' href='https://fonts.googleapis.com/css?family=Open+Sans:400,300'>
    <link rel='stylesheet prefetch' href='https://fonts.googleapis.com/icon?family=Material+Icons'>
<!--    <link rel="stylesheet" type="text/css" href="{{ url_for('static', filename='css/style3.css') }}">-->
    <link rel="stylesheet" type="text/css" href="{{ url_for('static', filename='css/style8.css') }}">
</head>
<body>
<p>      * Return to <a href="{{ url_for('main') }}" class="link">Main</a> page.       </p>
<p>                                          OR                                        </p>
<p>** Send us an e-mail <i>amitsanger1988@gmail.com</i> about this error and try later.</p>
<P>************************************************************************************</P>

    <h1>DIE</h1>
<h2>DEEP INFO EXTRACTOR</h2>
<p>
    <b>Deep Info Extractor (DIE)</b> is an open-source tool that can extract useful information from micro text. Name
    Entity Recognition is an example of an information extraction task and DIE can extract such information but taking
    one task at a time, i.e. tool can extract either name or entity, or location at a time. DIE tool can be trained on
    any labeled data that is in <a href="https://paperswithcode.com/dataset/conll-2003" target="_blank">Conl2003</a>
    format & provide 2 pre trained & 6 novel pre-processing embedding methods to choose from. The tool can be used with
    or without docker. Docker helps you to relax from the environment variations.
</p>
<h3>GETTING STARTED</h3>
<p><b>Video Tutorial:</b><a href="" target="_blank">youtube</a></p>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/sZRFoYydfc8"
            title="YouTube video player" frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
            allowfullscreen></iframe>


<h3>Download Dependencies & Trained Weights</h3>
<P>To run this project, you will need to download the DIE directory from the
    <a href="https://drive.google.com/drive/folders/1I6idw9pASneTJ5BPyD0cq6nNZ3YxXQnC?usp=sharing" target="_blank">google drive</a>.</P>

<table>
    <thead>
        <h4>Structure of the DIE directory</h4>
    </thead>
    <tr>
        <td><b>DIE</b></td>
        <td colspan="5"></td>
    </tr>
    <tr>
        <td></td>
        <td>|-- <b>Pre-Trained Embedding Model</b></td>
        <td colspan="4"></td>
    </tr>
    <tr>
        <td colspan="2"></td>
        <td>|-- bert-base-multilingual-cased</td>
        <td colspan="3"></td>
    </tr>
    <tr>
        <td colspan="2"></td>
        <td>|-- deberta-base</td>
        <td colspan="3"></td>
    </tr>
    <tr>
        <td colspan="2"></td>
        <td>|-- pos_tagger</td>
        <td colspan="3"></td>
    </tr>
    <tr>
        <td></td>
        <td>|-- <b>Trained Weights</b></td>
        <td colspan="4"></td>
    </tr>
    <tr>
        <td colspan="2"></td>
        <td>|-- Conll2003_Location</td>
        <td colspan="3"></td>
    </tr>
    <tr>
        <td colspan="3"></td>
        <td>|-- Conell</td>
        <td colspan="2"></td>
    </tr>
    <tr>
        <td colspan="4"></td>
        <td>|-- bert</td>
        <td></td>
    </tr>
     <tr>
        <td colspan="5"></td>
        <td>|-- lmr.pt</td>
    </tr>
    <tr>
        <td colspan="4"></td>
        <td>|-- bert_posam</td>
        <td></td>
    </tr>
      <tr>
        <td colspan="5"></td>
        <td>|-- lmr.pt</td>
    </tr>
    <tr>
        <td colspan="4"></td>
        <td>|-- deberta</td>
        <td></td>
    </tr>
      <tr>
        <td colspan="5"></td>
        <td>|-- lmr.pt</td>
    </tr>
    <tr>
        <td colspan="4"></td>
        <td>|-- deberta_posam</td>
        <td></td>
    </tr>
     <tr>
        <td colspan="5"></td>
        <td>|-- lmr.pt</td>
    </tr>
    <tr>
        <td colspan="4"></td>
        <td>|-- mdm</td>
        <td></td>
    </tr>
     <tr>
        <td colspan="5"></td>
        <td>|-- lmr.pt</td>
    </tr>
    <tr>
        <td colspan="4"></td>
        <td>|-- mdm_posam</td>
        <td></td>
    </tr>
     <tr>
        <td colspan="5"></td>
        <td>|-- lmr.pt</td>
    </tr>
    <tr>
        <td colspan="4"></td>
        <td>|-- vsm</td>
        <td></td>
    </tr>
   <tr>
        <td colspan="5"></td>
        <td>|-- lmr.pt</td>
    </tr>
    <tr>
        <td colspan="4"></td>
        <td>|-- vsm_posam</td>
        <td></td>
    </tr>
   <tr>
        <td colspan="5"></td>
        <td>|-- lmr.pt</td>
    </tr>
<!--    Conll2003_Organisation-->
     <tr>
        <td colspan="2"></td>
        <td>|-- Conll2003_Organisation</td>
        <td colspan="3"></td>
    </tr>
    <tr>
        <td colspan="3"></td>
        <td>|-- Conell</td>
        <td colspan="2"></td>
    </tr>
    <tr>
        <td colspan="4"></td>
        <td>|-- bert</td>
        <td></td>
    </tr>
     <tr>
        <td colspan="5"></td>
        <td>|-- lmr.pt</td>
    </tr>
    <tr>
        <td colspan="4"></td>
        <td>|-- bert_posam</td>
        <td></td>
    </tr>
      <tr>
        <td colspan="5"></td>
        <td>|-- lmr.pt</td>
    </tr>
    <tr>
        <td colspan="4"></td>
        <td>|-- deberta</td>
        <td></td>
    </tr>
      <tr>
        <td colspan="5"></td>
        <td>|-- lmr.pt</td>
    </tr>
    <tr>
        <td colspan="4"></td>
        <td>|-- deberta_posam</td>
        <td></td>
    </tr>
     <tr>
        <td colspan="5"></td>
        <td>|-- lmr.pt</td>
    </tr>
    <tr>
        <td colspan="4"></td>
        <td>|-- mdm</td>
        <td></td>
    </tr>
     <tr>
        <td colspan="5"></td>
        <td>|-- lmr.pt</td>
    </tr>
    <tr>
        <td colspan="4"></td>
        <td>|-- mdm_posam</td>
        <td></td>
    </tr>
     <tr>
        <td colspan="5"></td>
        <td>|-- lmr.pt</td>
    </tr>
    <tr>
        <td colspan="4"></td>
        <td>|-- vsm</td>
        <td></td>
    </tr>
   <tr>
        <td colspan="5"></td>
        <td>|-- lmr.pt</td>
    </tr>
    <tr>
        <td colspan="4"></td>
        <td>|-- vsm_posam</td>
        <td></td>
    </tr>
   <tr>
        <td colspan="5"></td>
        <td>|-- lmr.pt</td>
    </tr>
<!--    Conll2003_Person-->
     <tr>
        <td colspan="2"></td>
        <td>|-- Conll2003_Person</td>
        <td colspan="3"></td>
    </tr>
    <tr>
        <td colspan="3"></td>
        <td>|-- Conell</td>
        <td colspan="2"></td>
    </tr>
    <tr>
        <td colspan="4"></td>
        <td>|-- bert</td>
        <td></td>
    </tr>
     <tr>
        <td colspan="5"></td>
        <td>|-- lmr.pt</td>
    </tr>
    <tr>
        <td colspan="4"></td>
        <td>|-- bert_posam</td>
        <td></td>
    </tr>
      <tr>
        <td colspan="5"></td>
        <td>|-- lmr.pt</td>
    </tr>
    <tr>
        <td colspan="4"></td>
        <td>|-- deberta</td>
        <td></td>
    </tr>
      <tr>
        <td colspan="5"></td>
        <td>|-- lmr.pt</td>
    </tr>
    <tr>
        <td colspan="4"></td>
        <td>|-- deberta_posam</td>
        <td></td>
    </tr>
     <tr>
        <td colspan="5"></td>
        <td>|-- lmr.pt</td>
    </tr>
    <tr>
        <td colspan="4"></td>
        <td>|-- mdm</td>
        <td></td>
    </tr>
     <tr>
        <td colspan="5"></td>
        <td>|-- lmr.pt</td>
    </tr>
    <tr>
        <td colspan="4"></td>
        <td>|-- mdm_posam</td>
        <td></td>
    </tr>
     <tr>
        <td colspan="5"></td>
        <td>|-- lmr.pt</td>
    </tr>
    <tr>
        <td colspan="4"></td>
        <td>|-- vsm</td>
        <td></td>
    </tr>
   <tr>
        <td colspan="5"></td>
        <td>|-- lmr.pt</td>
    </tr>
    <tr>
        <td colspan="4"></td>
        <td>|-- vsm_posam</td>
        <td></td>
    </tr>
   <tr>
        <td colspan="5"></td>
        <td>|-- lmr.pt</td>
    </tr>
</table>
<p>*In Pre-Trained Embedding Model directory you get pre-Trained SOTA weights which you need to place while you running DIE on normal environment. On Docker environment you need not to do anything, everything is already set up in the image.
</p>
<p>
**In Trained Weights directory you will get trained models on 2 SOTA embeddings & 6 DIE novel embeddings methods. You can use them for your usage.
</p>

<h3>INSTALLATION</h3>
<h4>With Docker:</h4>
<p>The best way to use DIE is with Docker, as with docker you get environment ready built without the worry of
    dependencies.</p>
<p><i>install docker</i></p>
<p><i>initialize docker</i></p>
<p><i>docker pull gateid/die:(latest_version)</i></p>
<p>*latest_version: See the
    <a href="https://hub.docker.com/r/gateid/die/tags" target="_blank">DIE docker image</a> for details about latest version.</p>


<h4>Without Docker:</h4>
<p>Clone the project</p>
<p><i>git clone https://github.com/amitsanger3/DeepInfoExtractor</i></p>
<p>Go to the project directory</p>
<p><i>cd DeepInfoExtractor</i></p>
<p>Place all directories which is in 'Pre-Trained Embeddings Model' directory which you download from google drive.</p>
<p><i>bert-base-multilingual-cased<br>
  deberta-base<br>
  pos_tagger</i></p>
<p>Install dependencies</p>
<p><i>pip install -r lmr_requirements.txt </i></p>
<p>Open config.py file and change the 'API CONFIG' section as per the description</p>
<p><i># ####################### API CONFIGS ######################################<br>
# Change the  below location with the complete path of your loca dirs <br>
# as mention below<br>
<br>
conell_files_dir = "/geoai/data/conll2003/"  # Path where your conll2003/dataset dir is placed<br>
conell_train_file = "/geoai/data/conll2003/train.txt"  # Path where your conll2003/dataset train file is placed in conll2003 format<br>
conell_valid_file = "/geoai/data/conll2003/dev.txt"  # Path where your conll2003/dataset validation file is placed in conll2003 format<br>
conell_test_file = "/geoai/data/conll2003/test.txt"  # Path where your conll2003/dataset  test file is placed in conll2003 format<br>
<br>
model_path = "/geoai/TRAINED_MODEL/Conell/"  # Path where you want your trained model will be saved<br>
logs_path = "/geoai/LOGS/Conell/"  # Path where you want your logs will be saved<br>
# ##########################################################################
</i></p>
<p>Start the flask app</p>
<p><i>python api_run.py</i></p>
<p>Open your browser and enter the below domain</p>
<p><i>https://your_system_local_ip:5000/main</i></p>
<p>**e.g. : https://192.168.22.200:5000/main</p>
<p>VOILA !!!
<br>
The GUI app is started. Now, do the training & predictions as shown in Demo above.</p>

<h3>Acknowledgements</h3>

 <p>- <a href="https://docs.docker.com/engine/" target="_blank">Docker Installation</a></p>
 <p>- <a href="https://arxiv.org/abs/1810.04805" target="_blank">BERT</a></p>
<p>- <a href="https://arxiv.org/abs/2006.03654" target="_blank">Deberta</a></p>


<h3>Support</h3>

<p>For support, email <i>amitsanger1988@gmail.com</i> or join
    <a href="https://www.youtube.com/@AmitSangerdes" target="_blank">Youtube channel</a></p>


</body>
</html>